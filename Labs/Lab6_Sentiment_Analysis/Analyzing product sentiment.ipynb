{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación: Prediciendo sentimiento de reviews de productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://dealnews.a.ssl.fastly.net/files/uploads/funny-amazon-reviews-horse-head-mask-3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataset\n",
    "'amazon_baby.csv' contiene información de reviews de productos de bebe en Amazon. El propósito de este caso de estudio es construir un clasificador de sentimiento que pueda predecir si el review de un producto es positivo o negativo. \n",
    "\n",
    "Dentro del dataset se tiene los siguientes datos:\n",
    "1. `review`: Texto del review escrito por un usuario\n",
    "2. `name`: Nombre del producto\n",
    "3. `rating`: Rating del 1 al 5\n",
    "Existen muchas técnicas para el análisis de sentimiento en texto hoy en día, pero para efectos de este caso, el análisis de sentimiento lo realizaremos usando un conteo de palabras. \n",
    "\n",
    "Por ejemplo: Para el review \"the sushi was good and the service was excellent\" se generaría el conteo de palabras:\n",
    "\"the\": 2\n",
    "\"sushi\": 1\n",
    "\"was\": 2\n",
    "\"good\": 1\n",
    "\"and\" 1\n",
    "\"service\": 1\n",
    "\"excelente\": 1\n",
    "\n",
    "1. Usa `CountVectorize`que se encuentra en klearn.feature_extraction.text para obtener lo feature para tu modelo\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "2. Ahora usa `TfidfVectorizer` para obtgener los features para tu modelo y compáralo contra el anterior\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183531, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon_baby.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el própostio de este laboratorio, nos enfocaremos en la columna **review** y **rating**.\n",
    "  \n",
    "Empecemos por limpiar el dataframe, borrando todas las rows con datos nulos y limpiamos de las rows todo aquello que no sea letra o dígitos.  \n",
    "La columna **rating**, va del 1 al 5, y en varios ejemplos eliminan las columnas con rating de 3, porque sería como un sentimiento neutral y no ayuda a la creación del modelo. Entonces agregaremos una columna **\"Positivity\"**, donde los ratings mayores a 3 se les asigna un valor de **1**, indicando que el sentimiento es **positivo**. De otra forma será **0**, indicando un sentimiento **negativo**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166456, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna({'review':''})  # fill in N/A's in the review column\n",
    "import string\n",
    "df['review']=df['review'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "#df = df[pd.notnull(df['review'])]\n",
    "df = df[df['rating'] != 3]\n",
    "df['Positivity'] = np.where(df['rating'] > 3, 1, 0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>Positivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  Positivity  \n",
       "1  it came early and was not disappointed i love ...       5           1  \n",
       "2  Very soft and comfortable and warmer than it l...       5           1  \n",
       "3  This is a product well worth the purchase  I h...       5           1  \n",
       "4  All of my kids have cried nonstop when I tried...       5           1  \n",
       "5  When the Binky Fairy came to our house we didn...       5           1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, le hacemos split a la data en un substet para un **training set** y un **test set**, usando **review** y **Positivity**. El split será de 80-20, e imprimimos la primera review para fines didacticos y el shape del training y el test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry: \n",
      "\n",
      " I am editing this review since I have now used this item for a yearProsI liked the colors i chose they were as depicted when i was shopping for it  i bought white n beigeCons i find that the wood is painted poorly you can see stroke like residue and seems that it needed another hand or soIt looks kind of sloppy as well some bloches of paint In my opinion it is kind of expensive when it comes to the condition you  get the wood inIt makes a loud cracking noise every time I rock my baby to sleepThis is very infuriating when trying to get a baby to sleepOne of the iron springs keeps popping out and I need my husband to put it back in for meI am 115 lb so this has nothing to do with weightOverall if you are going to use it just to relax in it is fineIf you are trying to rock your baby to sleep forget it\n",
      "\n",
      "\n",
      "X_train shape:  (133164,)\n",
      "\n",
      "\n",
      "X_test shape:  (33292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['Positivity'],test_size = 0.20, random_state = 1)\n",
    "print('X_train first entry: \\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)\n",
    "print('\\n\\nX_test shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el **X_train**, podemos ver que tenemos una colección de más 133 mil reviews y más de 33 mil para **test**. Para poder aplicar machine learning a estos reviews o \"documentos de texto\", tenemos que convertir el contenido del texto en vectores de caracteríosticas númericas para usar con Scikit-Learn.\n",
    "\n",
    "## Modelos\n",
    "  \n",
    "### CountVecotorizer-Bags-of-words\n",
    "  \n",
    "La manera más fácil de hacer esto, es usando la representación **bags-of-words**, que ignora la estructura y simplemente cuenta cuántas veces aparece cada palabra. **CountVectorizer**, nos permite usar el approach de bags-of-words al convertir una colección de documentos de texto en una matrix de recuentos de tokens. \n",
    "\n",
    "Para entenderlo mejor, veamos una representación gráfica de una Bag of words:\n",
    "\n",
    "<img src='https://www.novuslight.com/uploads/n/BagofWords.jpg'>\n",
    "\n",
    "Ok, quizás sea necesaria una mejpor representación gráfica:\n",
    "\n",
    "<img src='http://images4.programmersought.com/947/0a/0acb9279d17a1631bcfb154583cca443.JPEG'>\n",
    "\n",
    "  \n",
    "Instanciamos el CountVectorizer y lo ajustamos a nuestra training data, conviertiendo nuestra colección de textos en una matriz de recuentos de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer().fit(X_train)\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo tiene muchos paramentros, pero los valores por default nos sirven así como están. \n",
    "\n",
    "La configuración predeterminada tokeniza la cadena, extrayendo palabras de al menos 2 letras o números, separadas por límites de palabras, luego convierte todo en minúsculas y construye un vocabulario usando estos tokens. Podemos obtener algunos de los vocabularios usando el método **get_feature_names** de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['140',\n",
       " '5hrs',\n",
       " 'anywherefeaturesthe',\n",
       " 'beingeasily',\n",
       " 'byfisherprice',\n",
       " 'colorsstyles',\n",
       " 'daughgter',\n",
       " 'dropscomes',\n",
       " 'fangod',\n",
       " 'gdiapers',\n",
       " 'herespend',\n",
       " 'iraqup',\n",
       " 'limitssafe',\n",
       " 'misgivings',\n",
       " 'nosefrida',\n",
       " 'painsoreness',\n",
       " 'pregnet',\n",
       " 'reducer',\n",
       " 'seatjump',\n",
       " 'snugsecure',\n",
       " 'stylistic',\n",
       " 'threes',\n",
       " 'unfortuantely',\n",
       " 'wellrecently']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_feature_names()[1000::5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar esos vocabularios, podemos tener una pequeña idea de lo que tratan. Al verificar la longitud de get_feature_names, podemos ver que estamos trabajando con 119528 vocablos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119528"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, transformamos los documentos en **X_train** en una \"term matrix\", lo que nos da la representación de bags-of-word. El resultado se almacena en una sparse matrix de SciPy, donde cada row corresponde a un documento, y cada columna es una palabra de nuestro vocabulario de training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<133164x119528 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7025498 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vector.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas quedan representadas de la siguiente forma:\n",
    "\n",
    "<img src='https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/assets/feml_0405.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las entradas en esta matriz son el número de veces que cada palabra aparece en cada review. Ya que el número de palabras en el vocabulario es más grande que el número de palabras que pueden aparecer en una sola review, la mayoría de los elementos en la matriz son cero. \n",
    "  \n",
    "\n",
    "#### Logistic Regression  \n",
    "  \n",
    "Ahora, entrenaremos al clasificador de regresión logística, basado en matrix **X_train_vectorized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaimesolis/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jaimesolis/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119528"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "len(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, haremos predicciones usando X_test y calculando el score del area bajo la curva(probabilidad de que una palabra esté del lado correcto), la confusion matrix y sacando la precisión de nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8500912650136809\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 3873  1429]\n",
      " [  848 27142]]\n",
      "\n",
      "Precision: 0.9499842497637464\n",
      "Recall: 0.9697034655234013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "predictions = model.predict(vector.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(\"\\nPrecision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\",recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión podemos concluir que:  \n",
    "**True positive: 3873**(Predijimos valores positivos y fueron positivos)  \n",
    "**True negative: 27142**(Predijimos valores negativos y fueron negativos)  \n",
    "**False positive: 1429**(Predijimos valores positivos y fueron negativos)  \n",
    "**False negative: 848**(Predijimos valores negativos y fueron positivos)  \n",
    "\n",
    "**Accuracy = (TP+TN)/total**  \n",
    "**Accuracy = (3873+27142)/33292 ~ 93%**  \n",
    "**Error Rate = (FP+FN)/total**  \n",
    "**Error rate = (1429+848)/33292 ~7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado no es malo. Para comprender mejor cómo nuestro modelo hace estas predicciones, podemos usar los coeficientes para cada característica (una palabra) para determinar su peso en términos de positividad y negatividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['dissapointed' 'worst' 'useless' 'worthless' 'poorly' 'disappointing'\n",
      " 'poor' 'unusable' 'theory' 'ineffective' 'concept' 'pointless'\n",
      " 'unacceptable' 'returning' 'tomorrow']\n",
      "\n",
      "Largest Coefs: \n",
      "['lifesaver' 'saves' 'ply' 'downside' 'thankful' 'worry' 'awesome'\n",
      " 'relieved' 'glad' 'outstanding' 'skeptical' 'con' 'rich' 'minor']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vector.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:15]]))\n",
    "print('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-15:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ordenar los diez coeficientes más pequeños y diez más grandes, podemos ver que el modelo ha pronosticado palabras como “worst”, “disappointing” and “useless”\" a críticas negativas, y palabras como “lifesaver”, “glad”, and “oustanding” a reviews positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vector.transform(['The product is not good, I would never buy them again',\n",
    "                                    'The product is not bad, I will buy them again'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo actual clasificó erróneamente el documento “The product is not good, I will never buy them again” como una review positiva, y también clasificó erróneamente el documento \"“The product is not bad, I will buy them again” como una review negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sin embargo, nuestro modelo se puede mejorar. \n",
    "\n",
    "### Tf–idf term weighting  \n",
    "\n",
    "En reviews largos, algunas palabras estarán presentes muy a menudo pero llevarán muy poca información significativa sobre el contenido real del documento (como  “the”, “a” and “is”). Si tuviéramos que alimentar los datos de conteo directamente a un clasificador, esos términos muy frecuentes opacarían las frecuencias de términos más raros aún más interesantes. **Tf-idf** nos permite ponderar los términos en función de lo **importantes** que son para un documento.\n",
    "  \n",
    "Por lo tanto, crearemos una instancia del Tf–idf vectorizer y lo ajustaremos a nuestros datos de entrenamiento. Especificamos min_df = 5, que eliminará cualquier palabra de nuestro vocabulario que **aparezca** en menos de cinco documentos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20039"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vector = TfidfVectorizer(min_df = 5).fit(X_train)\n",
    "len(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaimesolis/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vector.transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.833365313823213\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 3639  1663]\n",
      " [  549 27441]]\n",
      "\n",
      "Precision: 0.9428600879604178\n",
      "Recall: 0.9803858520900322\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(vector.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"\\nPrecision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\",recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión podemos concluir que:  \n",
    "**True positive: 3639**(Predijimos valores positivos y fueron positivos)  \n",
    "**True negative: 27441**(Predijimos valores negativos y fueron negativos)  \n",
    "**False positive: 1663**(Predijimos valores positivos y fueron negativos)  \n",
    "**False negative: 549**(Predijimos valores negativos y fueron positivos)  \n",
    "\n",
    "**Accuracy = (TP+TN)/total**  \n",
    "**Accuracy = (3639+27441)/33292 ~ 93%**  \n",
    "**Error Rate = (FP+FN)/total**  \n",
    "**Error rate = (1663+549)/33292 ~7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, aunque pudimos reducir la cantidad de funciones de 119528 a solo 20039, nuestro AUC y Precisión se redujeron minimamente. \n",
    "\n",
    "Con el siguiente código, podemos obtener una lista de características con el tf-idf más pequeño que `aparece comúnmente en todas las revisiones o que rara vez aparece en reviews muy largas` y una lista de palabras con el tf-idf más grande contiene `palabras que aparecieron con frecuencia en una review, pero no aparecieron comúnmente en todas las revisiones`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Tfidf: \n",
      "['reviewfirst' 'situationthese' 'navigation' 'lockoffs' 'monthspros'\n",
      " 'definitive' 'ubiquitous' 'goso' 'topmost' 'modelthe']\n",
      "\n",
      "Largest Tfidf: \n",
      "['uacutetil' 'product' 'so' 'dd' 'excellent' 'excelente' 'excelent' 'love'\n",
      " 'adorable' 'fab']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vector.get_feature_names())\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "print('Smallest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vector.transform(['The product is not good, I will never buy them again',\n",
    "                                    'The product is not bad, I will buy them again'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo actual clasificó el documento “The product is not good, I will never buy them again” como una review negativa, pero también clasificó erróneamente el documento \"“The product is not bad, I will buy them again” como una review negativa.\n",
    "\n",
    "## n-grams  \n",
    "  \n",
    "Una forma de corregir esta clasificación errónea es agregar **n-grams**. Por ejemplo, los bigrams cuentan pares de palabras adyacentes, y podrían darnos características como \"bad\" o \"not bad\". Por lo tanto, estamos reajustando nuestro training especificando un min_df de 5 y extrayendo **1-grams** y **2-grams**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197286"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vector.transform(X_train)\n",
    "len(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaimesolis/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemeos más caracteristicas para el training, veamos si el score aumenta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8877920578144723\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 4233  1069]\n",
      " [  638 27352]]\n",
      "Precision: 0.9623869673832729\n",
      "Recall: 0.9772061450518043\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(vector.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, predictions))\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, predictions))\n",
    "print(\"Recall:\",recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión podemos concluir que:  \n",
    "**True positive: 3873**(Predijimos valores positivos y fueron positivos)  \n",
    "**True negative: 27142**(Predijimos valores negativos y fueron negativos)  \n",
    "**False positive: 1429**(Predijimos valores positivos y fueron negativos)  \n",
    "**False negative: 848**(Predijimos valores negativos y fueron positivos)  \n",
    "\n",
    "**Accuracy = (TP+TN)/total**  \n",
    "**Accuracy = (3873+27142)/33292 ~ 93%**  \n",
    "**Error Rate = (FP+FN)/total**  \n",
    "**Error rate = (1429+848)/33292 ~7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los coeficientes vamos a ver las caracteristicas con menor y mayor coeficiente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coef: \n",
      "['not recommend' 'not worth' 'two stars' 'not happy' 'useless'\n",
      " 'disappointing' 'poor' 'returned' 'disappointed' 'wouldn recommend']\n",
      "\n",
      "Largest Coef: \n",
      "['not too' 'perfect' 'awesome' 'just what' 'excellent' 'these work' 'glad'\n",
      " 'great' 'love' 'perfectly']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vector.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n",
    "print('Largest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:-11:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo ha predicho correctamente bigrams como “not recommend”, “not worth” a reviews negativas, y bigrams como “these work”, “excellent” como reviews positivas.   \n",
    "  \n",
    "#### Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vector.transform(['The product is not good, I would never buy them again',\n",
    "                                    'The product is not bad, I will buy them again', \n",
    "                                      'This shit is awesome',\n",
    "                                     'This shit doesnt work bad', \n",
    "                                     'this is totally a piece of shit'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último modelo identifica correctamente las reviews como negativas y positivas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://media2.giphy.com/media/lTpme2Po0hkqI/giphy.gif'>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
